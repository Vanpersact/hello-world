{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f03dec2",
   "metadata": {},
   "source": [
    "\n",
    "# Filtro de **Adjetivos** com Tolerância a Erros (PT-BR)  \n",
    "Cria uma tabela somente com **adjetivos** e seus quantitativos, a partir da lista de frequências de palavras.\n",
    "\n",
    "**Como usar**  \n",
    "- **Opção A — Arquivo**: informe `ARQUIVO = \"minha_lista.xlsx\"` (ou `.csv`) com colunas `Palavra` e `Frequência` (ou similares).  \n",
    "- **Opção B — Colar texto**: cole a lista na variável `COLAR_LISTA` (duas colunas, separadas por TAB ou por múltiplos espaços).\n",
    "\n",
    "O notebook:\n",
    "1. Normaliza (minúsculas, remove acentos, reduz repetições: `lotadoooo` → `lotadoo`);  \n",
    "2. Aplica **regras morfológicas** e um **léxico semente** de adjetivos;  \n",
    "3. Faz **fuzzy matching** leve (distância de edição) para capturar erros simples;  \n",
    "4. Agrupa por **lema** e exporta **Excel** com:\n",
    "   - `01_adjetivos_detalhado` (todas as formas encontradas),\n",
    "   - `02_adjetivos_agrupado` (somado por lema normalizado).\n",
    "\n",
    "> O método é **heurístico** (sem modelo pesado). Bom para começar; posso evoluir depois com POS-tagging.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6339fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# (Se estiver em ambiente novo como Colab, descomente para instalar dependências leves)\n",
    "# !pip install pandas openpyxl unidecode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db57415",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re, io, sys\n",
    "import pandas as pd\n",
    "from unidecode import unidecode\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple\n",
    "\n",
    "# ====================== CONFIGURAÇÃO ======================\n",
    "# Informe um arquivo OU cole o texto bruto.\n",
    "ARQUIVO = None  # ex.: \"frequencias.xlsx\" ou \"frequencias.csv\"  (deixe None se for colar texto)\n",
    "COLAR_LISTA = \"\"\"\n",
    "# Cole aqui (opcional): duas colunas — Palavra e Frequência (TAB ou múltiplos espaços)\n",
    "# Exemplo:\n",
    "# absurdo\t244\n",
    "# atrasada\t135\n",
    "# lotado\t383\n",
    "\"\"\"\n",
    "\n",
    "# Nomes possíveis das colunas no arquivo\n",
    "COLS_PALAVRA = {\"palavra\",\"termo\",\"token\",\"word\",\"texto\"}\n",
    "COLS_FREQ    = {\"frequencia\",\"freq\",\"quantidade\",\"qtd\",\"ocorrencias\",\"ocorrência\",\"contagem\",\"count\"}\n",
    "\n",
    "# ==========================================================\n",
    "\n",
    "def ler_tabela():\n",
    "    if ARQUIVO:\n",
    "        p = Path(ARQUIVO)\n",
    "        if not p.exists():\n",
    "            raise FileNotFoundError(f\"Arquivo não encontrado: {p.resolve()}\")\n",
    "        if p.suffix.lower() in [\".xlsx\", \".xls\"]:\n",
    "            df = pd.read_excel(p)\n",
    "        elif p.suffix.lower() == \".csv\":\n",
    "            # tenta separadores comuns\n",
    "            try:\n",
    "                df = pd.read_csv(p)\n",
    "            except Exception:\n",
    "                df = pd.read_csv(p, sep=\";\")\n",
    "        else:\n",
    "            raise ValueError(\"Forneça .xlsx/.xls ou .csv\")\n",
    "        cols_lower = {c.lower(): c for c in df.columns}\n",
    "        col_pal = None\n",
    "        col_freq = None\n",
    "        for k,v in cols_lower.items():\n",
    "            if k in COLS_PALAVRA and col_pal is None:\n",
    "                col_pal = v\n",
    "            if k in COLS_FREQ and col_freq is None:\n",
    "                col_freq = v\n",
    "        if col_pal is None or col_freq is None:\n",
    "            # tenta a primeira e segunda coluna como fallback\n",
    "            col_pal = list(df.columns)[0]\n",
    "            col_freq = list(df.columns)[1]\n",
    "        df = df[[col_pal, col_freq]].copy()\n",
    "        df.columns = [\"Palavra\",\"Frequencia\"]\n",
    "        return df\n",
    "    else:\n",
    "        # Parse do texto colado\n",
    "        bruto = COLAR_LISTA.strip().splitlines()\n",
    "        dados = []\n",
    "        for ln in bruto:\n",
    "            ln = ln.strip()\n",
    "            if not ln or ln.startswith(\"#\"):\n",
    "                continue\n",
    "            # tenta TAB, senão múltiplos espaços\n",
    "            if \"\\t\" in ln:\n",
    "                partes = ln.split(\"\\t\")\n",
    "            else:\n",
    "                partes = re.split(r\"\\s{2,}\", ln)  # 2+ espaços\n",
    "                if len(partes) == 1:\n",
    "                    partes = re.split(r\"\\s+\", ln, maxsplit=1)\n",
    "            if len(partes) >= 2:\n",
    "                w, f = partes[0].strip(), partes[1].strip()\n",
    "                dados.append((w, f))\n",
    "        df = pd.DataFrame(dados, columns=[\"Palavra\",\"Frequencia\"])\n",
    "        return df\n",
    "\n",
    "df_raw = ler_tabela()\n",
    "print(\"Linhas lidas:\", len(df_raw))\n",
    "df_raw.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f040e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------- Normalização ---------\n",
    "def normalizar_palavra(w: str) -> str:\n",
    "    w0 = str(w).strip()\n",
    "    w0 = w0.replace(\"’\",\"'\").replace(\"`\",\"'\")\n",
    "    w0 = unidecode(w0.lower())\n",
    "    # reduz repetições exageradas de letras: kkkkkk -> kk, lotadoooo -> lotadoo\n",
    "    w0 = re.sub(r\"(.)\\1{2,}\", r\"\\1\\1\", w0)\n",
    "    # remove pontuações nas pontas\n",
    "    w0 = re.sub(r\"^[^a-z]+|[^a-z]+$\", \"\", w0)\n",
    "    return w0\n",
    "\n",
    "def eh_palavra_valida(w: str) -> bool:\n",
    "    if not w: return False\n",
    "    # rejeita tokens com dígitos\n",
    "    if re.search(r\"\\d\", w): return False\n",
    "    # tamanho mínimo\n",
    "    if len(w) < 3: return False\n",
    "    return True\n",
    "\n",
    "df = df_raw.copy()\n",
    "df[\"Frequencia\"] = pd.to_numeric(df[\"Frequencia\"].astype(str).str.replace(\".\",\"\").str.replace(\",\",\".\"), errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"Frequencia\"])\n",
    "df[\"Frequencia\"] = df[\"Frequencia\"].astype(int)\n",
    "\n",
    "df[\"pal_norm\"] = df[\"Palavra\"].apply(normalizar_palavra)\n",
    "df = df[df[\"pal_norm\"].apply(eh_palavra_valida)].copy()\n",
    "df = df.groupby([\"pal_norm\"], as_index=False)[\"Frequencia\"].sum()\n",
    "print(\"Após normalização:\", len(df), \"tokens únicos\")\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78343d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------- Dicionário semente de adjetivos comuns (PT-BR) ---------\n",
    "ADJ_SEMENTE = {\n",
    "    # polaridade / qualidade geral\n",
    "    \"bom\",\"boa\",\"otimo\",\"otima\",\"excelente\",\"maravilhoso\",\"maravilhosa\",\"perfeito\",\"perfeita\",\n",
    "    \"ruim\",\"pessimo\",\"pessima\",\"horrivel\",\"terrivel\",\"mediano\",\"mediana\",\"regular\",\n",
    "    \"absurdo\",\"absurda\",\"inaceitavel\",\"inadmissivel\",\"incrivel\",\"deploravel\",\"insuportavel\",\n",
    "    \"impossivel\",\"desagradavel\",\"agradavel\",\"necessario\",\"desnecessario\",\"essencial\",\n",
    "    \"complicado\",\"complicada\",\"simples\",\"facil\",\"dificil\",\"rapido\",\"rapida\",\"lento\",\"lenta\",\n",
    "    \"caro\",\"cara\",\"barato\",\"barata\",\"cheio\",\"cheia\",\"vazio\",\"vazia\",\"sujo\",\"suja\",\"limpo\",\"limpa\",\n",
    "    \"escuro\",\"escura\",\"claro\",\"clara\",\"seguro\",\"segura\",\"perigoso\",\"perigosa\",\n",
    "    \"eficiente\",\"ineficiente\",\"competente\",\"incompetente\",\n",
    "    \"confortavel\",\"desconfortavel\",\"normal\",\"anormal\",\n",
    "    \"frio\",\"fria\",\"quente\",\"gelado\",\"gelada\",\"lotado\",\"lotada\",\"lotados\",\"lotadas\",\n",
    "    \"atrasado\",\"atrasada\",\"adiantado\",\"adiantada\",\n",
    "    \"barulhento\",\"barulhenta\",\"silencioso\",\"silenciosa\",\n",
    "    \"higienico\",\"higienica\",\"insalubre\",\"salubre\",\n",
    "    \"legal\",\"ilegal\",\"justo\",\"injusto\",\"honesto\",\"desonesto\",\n",
    "    \"educado\",\"educada\",\"gentil\",\"grossa\",\"grosso\",\"nojento\",\"nojenta\",\n",
    "    \"grande\",\"pequeno\",\"alto\",\"baixa\",\"baixo\",\"tenso\",\"tensa\",\"calmo\",\"calma\",\n",
    "    \"preciso\",\"impreciso\",\"correto\",\"incorreto\",\"verdadeiro\",\"falso\",\n",
    "    \"otimizado\",\"otimizada\",\"minimo\",\"maximo\",\"minima\",\"maxima\",\n",
    "    \"horrendo\",\"horrenda\",\"horroroso\",\"horrorosa\",\"terrivel\",\n",
    "    \"lindo\",\"linda\",\"bonito\",\"bonita\",\"feio\",\"feia\"\n",
    "}\n",
    "\n",
    "# Reduções/lematizações simples (agrupar formas flexionadas no mesmo lema)\n",
    "LEMA_EQUIV = {\n",
    "    \"boas\":\"boa\", \"bons\":\"bom\", \"melhor\":\"bom\", \"melhores\":\"bom\",\n",
    "    \"pior\":\"pessimo\", \"piores\":\"pessimo\",\n",
    "    \"otimos\":\"otimo\",\"otimas\":\"otima\",\"excelentes\":\"excelente\",\n",
    "    \"maravilhosos\":\"maravilhoso\",\"maravilhosas\":\"maravilhosa\",\n",
    "    \"absurdos\":\"absurdo\",\"absurdas\":\"absurda\",\"absurso\":\"absurdo\",\n",
    "    \"inaceitaveis\":\"inaceitavel\",\"inadmissiveis\":\"inadmissivel\",\n",
    "    \"rapidos\":\"rapido\",\"rapidas\":\"rapida\",\"lentos\":\"lento\",\"lentas\":\"lenta\",\n",
    "    \"caros\":\"caro\",\"caras\":\"cara\",\"baratos\":\"barato\",\"baratas\":\"barata\",\n",
    "    \"cheios\":\"cheio\",\"cheias\":\"cheia\",\"vazios\":\"vazio\",\"vazias\":\"vazia\",\n",
    "    \"sujos\":\"sujo\",\"sujas\":\"suja\",\"limpos\":\"limpo\",\"limpas\":\"limpa\",\n",
    "    \"claros\":\"claro\",\"claras\":\"clara\",\"escuros\":\"escuro\",\"escuras\":\"escura\",\n",
    "    \"seguros\":\"seguro\",\"seguras\":\"segura\",\"perigosos\":\"perigoso\",\"perigosas\":\"perigosa\",\n",
    "    \"eficientes\":\"eficiente\",\"competentes\":\"competente\",\"incompetentes\":\"incompetente\",\n",
    "    \"confortaveis\":\"confortavel\",\"desconfortaveis\":\"desconfortavel\",\n",
    "    \"normais\":\"normal\",\"anormais\":\"anormal\",\n",
    "    \"frios\":\"frio\",\"frias\":\"fria\",\"quentes\":\"quente\",\"gelados\":\"gelado\",\"geladas\":\"gelada\",\n",
    "    \"lotados\":\"lotado\",\"lotadas\":\"lotada\",\"lotaderrimo\":\"lotado\",\"lotadissimo\":\"lotado\",\"lotaderrima\":\"lotada\",\"lotadissima\":\"lotada\",\n",
    "    \"atrasados\":\"atrasado\",\"atrasadas\":\"atrasada\",\"adiantados\":\"adiantado\",\"adiantadas\":\"adiantada\",\n",
    "    \"barulhentos\":\"barulhento\",\"barulhentas\":\"barulhenta\",\n",
    "    \"insalubres\":\"insalubre\",\n",
    "    \"justos\":\"justo\",\"injustos\":\"injusto\",\"honestos\":\"honesto\",\"desonestos\":\"desonesto\",\n",
    "    \"educados\":\"educado\",\"educadas\":\"educada\",\"gentis\":\"gentil\",\"grossos\":\"grosso\",\"grossas\":\"grossa\",\n",
    "    \"nojentos\":\"nojento\",\"nojentas\":\"nojenta\",\n",
    "    \"grandes\":\"grande\",\"pequenos\":\"pequeno\",\"pequenas\":\"pequeno\",\n",
    "    \"altos\":\"alto\",\"altas\":\"alto\",\"baixos\":\"baixo\",\"baixas\":\"baixo\",\n",
    "    \"tensos\":\"tenso\",\"tensas\":\"tensa\",\"calmos\":\"calmo\",\"calmas\":\"calma\",\n",
    "    \"precisos\":\"preciso\",\"imprecisos\":\"impreciso\",\"corretos\":\"correto\",\"incorretos\":\"incorreto\",\n",
    "    \"verdadeiros\":\"verdadeiro\",\"falsos\":\"falso\",\n",
    "    \"minimos\":\"minimo\",\"maximos\":\"maximo\",\"minimas\":\"minima\",\"maximas\":\"maxima\",\n",
    "    \"horrendos\":\"horrendo\",\"horrendas\":\"horrenda\",\"horrorosos\":\"horroroso\",\"horrorosas\":\"horrorosa\",\n",
    "    \"terriveis\":\"terrivel\",\"feios\":\"feio\",\"feias\":\"feia\",\"bonitos\":\"bonito\",\"bonitas\":\"bonita\",\n",
    "}\n",
    "\n",
    "def lema_normal(w: str) -> str:\n",
    "    return LEMA_EQUIV.get(w, w)\n",
    "\n",
    "# --------- Distância de edição simples (Levenshtein) ---------\n",
    "def lev_dist(a: str, b: str) -> int:\n",
    "    # otimização simples\n",
    "    if a == b: return 0\n",
    "    if abs(len(a)-len(b)) > 2:  # atalho: longe demais\n",
    "        return 99\n",
    "    m, n = len(a), len(b)\n",
    "    dp = list(range(n+1))\n",
    "    for i, ca in enumerate(a, 1):\n",
    "        prev, dp[0] = dp[0], i\n",
    "        for j, cb in enumerate(b, 1):\n",
    "            cur = min(\n",
    "                dp[j] + 1,\n",
    "                dp[j-1] + 1,\n",
    "                prev + (ca != cb)\n",
    "            )\n",
    "            prev, dp[j] = dp[j], cur\n",
    "    return dp[n]\n",
    "\n",
    "# --------- Heurísticas de \"parece adjetivo\" ---------\n",
    "SUFIXOS_ADJ = (\n",
    "    \"vel\",\"veis\",\"ivel\",\"iveis\",\"avel\",\"aveis\",\n",
    "    \"oso\",\"osa\",\"osos\",\"osas\",\n",
    "    \"ado\",\"ada\",\"ados\",\"adas\",\n",
    "    \"ido\",\"ida\",\"idos\",\"idas\",\n",
    "    \"ento\",\"enta\",\"entos\",\"entas\",\n",
    "    \"ante\",\"antes\",\"ente\",\"entes\",\n",
    "    \"al\",\"ais\",\"ar\",\"ares\",\"ario\",\"aria\",\"arios\",\"arias\",\n",
    "    \"udo\",\"uda\",\"udos\",\"udas\",\n",
    ")\n",
    "def parece_adjetivo(w: str) -> bool:\n",
    "    # regras rápidas\n",
    "    if w in ADJ_SEMENTE: return True\n",
    "    if any(w.endswith(s) for s in SUFIXOS_ADJ):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# --------- Mapeamento por fuzzy p/ erros simples ---------\n",
    "def fuzzy_mapeia_adjetivo(w: str) -> tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Se 'w' for (ou parecer) adjetivo, retorna (lema, motivo). Caso contrário, (\"\",\"\").\n",
    "    \"\"\"\n",
    "    w0 = lema_normal(w)\n",
    "    if w0 in ADJ_SEMENTE:\n",
    "        return w0, \"lexico\"\n",
    "    if parece_adjetivo(w0):\n",
    "        return w0, \"regra\"\n",
    "    # tenta aproximar aos lemas do dicionário semente\n",
    "    melhor = None\n",
    "    melhor_d = 99\n",
    "    for cand in ADJ_SEMENTE:\n",
    "        d = lev_dist(w0, cand)\n",
    "        if d < melhor_d:\n",
    "            melhor_d, melhor = d, cand\n",
    "    # tolerâncias: 1 para curtas (<=5), 2 para outras\n",
    "    tol = 1 if len(w0) <= 5 else 2\n",
    "    if melhor_d <= tol:\n",
    "        return melhor, f\"fuzzy(d={melhor_d})\"\n",
    "    return \"\", \"\"\n",
    "\n",
    "# Aplica\n",
    "saida_linhas = []\n",
    "for _, row in df.iterrows():\n",
    "    w = row[\"pal_norm\"]\n",
    "    freq = int(row[\"Frequencia\"])\n",
    "    lema, motivo = fuzzy_mapeia_adjetivo(w)\n",
    "    if lema:\n",
    "        saida_linhas.append({\n",
    "            \"adjetivo_encontrado\": w,\n",
    "            \"frequencia\": freq,\n",
    "            \"lema_normalizado\": lema,\n",
    "            \"criterio\": motivo\n",
    "        })\n",
    "\n",
    "df_adj = pd.DataFrame(saida_linhas)\n",
    "df_adj = df_adj.sort_values([\"lema_normalizado\",\"frequencia\"], ascending=[True, False]).reset_index(drop=True)\n",
    "print(\"Adjetivos detectados:\", len(df_adj))\n",
    "df_adj.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee40a89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------- Agrupa por lema ---------\n",
    "df_grp = df_adj.groupby(\"lema_normalizado\", as_index=False)[\"frequencia\"].sum()\n",
    "df_grp = df_grp.sort_values(\"frequencia\", ascending=False).reset_index(drop=True)\n",
    "df_grp.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008c8ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------- Exporta Excel ---------\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "out_path = Path(\"adjetivos_filtrados.xlsx\")\n",
    "with pd.ExcelWriter(out_path, engine=\"openpyxl\") as xls:\n",
    "    df_adj.to_excel(xls, sheet_name=\"01_adjetivos_detalhado\", index=False)\n",
    "    df_grp.to_excel(xls, sheet_name=\"02_adjetivos_agrupado\", index=False)\n",
    "print(\"Arquivo gerado:\", out_path.resolve())\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
